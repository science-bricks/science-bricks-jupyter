{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Act\n\nFor an [Intelligent Agent](intelligent_agent.ipynb), to [act](act.ipynb) is to select an output $a_t \\in A$.\n\n- The set of all possible actions is called the **Action Space** $A$.\n\n- Each **action** $a_t$ makes the agent **transition** from **state** $s_t$ to the state $s_{t+1}$ through its **state-transition probability distribution** or its **stochastic dynamics**:\n\n$$\ns_{t+1} \\sim \\mathbb{P}(s_{t+1} | s_t,a_t) \\iff s_{t+1} = f_t(s_t, a_t, u_t) \\quad u_t \\sim \\mathbb{P}_u\n$$\n\n<div align=\"center\">\n<img src=\"./img/rl_car.png\" width=\"425\" height=\"350\">\n</div>\n\n<div align=\"center\">\nSuper-Human Performance in Gran Turismo Sport Using Deep Reinforcement Learning [<a href=\"https://arxiv.org/pdf/2008.07971.pdf\">Fuchs et. al., 2021</a>]\n</div>",
      "metadata": {},
      "id": "2ac0baa9-412e-42a8-8ed9-25761728e1ac"
    }
  ]
}