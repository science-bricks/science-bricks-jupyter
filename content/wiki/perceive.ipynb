{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f6f3e4-1a58-4b03-a223-6f9c63b8ab3d",
   "metadata": {},
   "source": [
    "# Perceive\n",
    "\n",
    "For an [Intelligent Agent](intelligent_agent.ipynb) to [perceive](perceive.ipynb) is to [infer](infer.ipynb), from all data collected up to time $t$, its [state](state.ipynb) $s_t \\in S$.\n",
    "\n",
    "among all possible states from the [State Space](state_space.ipynb) $S$.\n",
    "\n",
    "into a [Markov State](markov_state.ipynb) $s_t \\in S$ of some [State Space](state_space.ipynb) $S$.\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(s_{t} \\mid s_{t-1}) = \n",
    "\\mathbb{P}(s_{t} \\mid s_{t-1}, s_{t-2}, \\ldots, s_0)\n",
    "$$\n",
    "\n",
    "The set of all possible states is called the [State Space](state_space.ipynb) $S$.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"./img/slam3.png\" width=\"425\" height=\"350\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "Spatial AI. From images to objects [<a href=\"https://openaccess.thecvf.com/content_cvpr_2013/papers/Salas-Moreno_SLAM_Simultaneous_Localisation_2013_CVPR_paper.pdf\">Salas-Moreno et. al., 2013</a>]\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
